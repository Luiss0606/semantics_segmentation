{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Concatenate, UpSampling2D\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_unet_model(input_size=(128, 128, 3), num_classes=1, segmentation_type='binary'):\n",
    "    # Base preentrenada de MobileNetV2\n",
    "    base_model = MobileNetV2(input_shape=input_size, include_top=False)\n",
    "    \n",
    "    # Capas de interés del modelo base para la conexión\n",
    "    layer_names = [\n",
    "        'block_1_expand_relu',   # 64x64\n",
    "        'block_3_expand_relu',   # 32x32\n",
    "        'block_6_expand_relu',   # 16x16\n",
    "        'block_13_expand_relu',  # 8x8\n",
    "        'block_16_project',      # 4x4\n",
    "    ]\n",
    "    layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "    # Crear el modelo de extracción de características\n",
    "    down_stack = Model(inputs=base_model.input, outputs=layers)\n",
    "    down_stack.trainable = False\n",
    "\n",
    "    # Definición de la parte ascendente del U-Net\n",
    "    up_stack = [\n",
    "        UpSampling2D((2, 2)),  # 4x4 -> 8x8\n",
    "        UpSampling2D((2, 2)),  # 8x8 -> 16x16\n",
    "        UpSampling2D((2, 2)),  # 16x16 -> 32x32\n",
    "        UpSampling2D((2, 2)),  # 32x32 -> 64x64\n",
    "    ]\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=input_size)\n",
    "    x = inputs\n",
    "\n",
    "    # Descenso en el U-Net\n",
    "    skips = down_stack(x)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Ascenso en el U-Net y concatenación con las capas de salto\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # Capa final de convolución dependiendo del tipo de segmentación\n",
    "    if segmentation_type == 'binary':\n",
    "        x = Conv2D(1, 3, padding='same', activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        x = Conv2D(num_classes, 3, padding='same', activation='softmax')(x)\n",
    "        loss = 'sparse_categorical_crossentropy'\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Configuración del modelo\n",
    "model = create_unet_model(segmentation_type='nobynary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks\n",
      "Resizing test images and masks\n",
      "Resizing validation images and masks\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "TRAIN_PATH = '/home/luishuingo/semantics_segmentation/Floor-Segmentationv1/train'\n",
    "TEST_PATH = '/home/luishuingo/semantics_segmentation/Floor-Segmentationv1/test'\n",
    "VALID_PATH = '/home/luishuingo/semantics_segmentation/Floor-Segmentationv1/valid/'\n",
    "\n",
    "X_train = np.zeros((len(os.listdir(TRAIN_PATH)), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(os.listdir(TRAIN_PATH)), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "\n",
    "print('Resizing training images and masks')\n",
    "\n",
    "for n, id_ in enumerate(os.listdir(TRAIN_PATH)):\n",
    "    \n",
    "    # Load and resize the training image\n",
    "    img = cv2.imread(os.path.join(TRAIN_PATH, id_))  # Read the image using OpenCV\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB if necessary\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)  # Resize the image\n",
    "    X_train[n] = img\n",
    "\n",
    "    # Load and resize the corresponding mask\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "    mask_ = cv2.imread(os.path.join(TRAIN_PATH, id_.replace('.jpg', '_mask.png')), cv2.IMREAD_GRAYSCALE)  # Read the mask as grayscale\n",
    "    mask_ = cv2.resize(mask_, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)  # Resize the mask\n",
    "    mask_ = np.expand_dims(mask_, axis=-1)\n",
    "    mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Now we do the same for the test set\n",
    "X_test = np.zeros((len(os.listdir(TEST_PATH)), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_test = np.zeros((len(os.listdir(TEST_PATH)), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "\n",
    "print('Resizing test images and masks')\n",
    "\n",
    "for n, id_ in enumerate(os.listdir(TEST_PATH)):\n",
    "\n",
    "    # Load and resize the training image\n",
    "    img = cv2.imread(os.path.join(TEST_PATH, id_))  # Read the image using OpenCV\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB if necessary\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)  # Resize the image\n",
    "    X_test[n] = img\n",
    "\n",
    "    # Load and resize the corresponding mask\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "    mask_ = cv2.imread(os.path.join(TEST_PATH, id_.replace('.jpg', '_mask.png')), cv2.IMREAD_GRAYSCALE)  # Read the mask as grayscale\n",
    "    mask_ = cv2.resize(mask_, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)  # Resize the mask\n",
    "    mask_ = np.expand_dims(mask_, axis=-1)\n",
    "    mask = np.maximum(mask, mask_)\n",
    "    Y_test[n] = mask\n",
    "\n",
    "# Now we do the same for the validation set\n",
    "\n",
    "X_valid = np.zeros((len(os.listdir(VALID_PATH)), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_valid = np.zeros((len(os.listdir(VALID_PATH)), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "\n",
    "print('Resizing validation images and masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " model_6 (Functional)        [(None, 64, 64, 96),         1841984   ['input_8[0][0]']             \n",
      "                              (None, 32, 32, 144),                                                \n",
      "                              (None, 16, 16, 192),                                                \n",
      "                              (None, 8, 8, 576),                                                  \n",
      "                              (None, 4, 4, 320)]                                                  \n",
      "                                                                                                  \n",
      " up_sampling2d_12 (UpSampli  (None, 8, 8, 320)            0         ['model_6[0][4]']             \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenat  (None, 8, 8, 896)            0         ['up_sampling2d_12[0][0]',    \n",
      " e)                                                                  'model_6[0][3]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_13 (UpSampli  (None, 16, 16, 896)          0         ['concatenate_12[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenat  (None, 16, 16, 1088)         0         ['up_sampling2d_13[0][0]',    \n",
      " e)                                                                  'model_6[0][2]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_14 (UpSampli  (None, 32, 32, 1088)         0         ['concatenate_13[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenat  (None, 32, 32, 1232)         0         ['up_sampling2d_14[0][0]',    \n",
      " e)                                                                  'model_6[0][1]']             \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampli  (None, 64, 64, 1232)         0         ['concatenate_14[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenat  (None, 64, 64, 1328)         0         ['up_sampling2d_15[0][0]',    \n",
      " e)                                                                  'model_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 1)            11953     ['concatenate_15[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1853937 (7.07 MB)\n",
      "Trainable params: 11953 (46.69 KB)\n",
      "Non-trainable params: 1841984 (7.03 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1131, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1225, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/metrics/base_metric.py\", line 723, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/metrics/accuracy_metrics.py\", line 395, in binary_accuracy\n        metrics_utils.binary_matches(y_true, y_pred, threshold), axis=-1\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/utils/metrics_utils.py\", line 932, in binary_matches\n        return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 128 and 64 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](Cast_1, Cast_3)' with input shapes: [?,128,128,1], [?,64,64,1].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/luishuingo/semantics_segmentation/training_v2.0 copy.ipynb Celda 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luishuingo/semantics_segmentation/training_v2.0%20copy.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m checkpointer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mmodel_for_nuclei.h5\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luishuingo/semantics_segmentation/training_v2.0%20copy.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luishuingo/semantics_segmentation/training_v2.0%20copy.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m               tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luishuingo/semantics_segmentation/training_v2.0%20copy.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m               tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/luishuingo/semantics_segmentation/training_v2.0%20copy.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, validation_data\u001b[39m=\u001b[39;49m(X_valid, Y_valid), batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49mcallbacks,)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file1dkv4kp4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1131, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1225, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 620, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/utils/metrics_utils.py\", line 77, in decorated\n        result = update_state_fn(*args, **kwargs)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/metrics/base_metric.py\", line 723, in update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/metrics/accuracy_metrics.py\", line 395, in binary_accuracy\n        metrics_utils.binary_matches(y_true, y_pred, threshold), axis=-1\n    File \"/home/luishuingo/anaconda3/envs/tf_seg/lib/python3.9/site-packages/keras/src/utils/metrics_utils.py\", line 932, in binary_matches\n        return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\n\n    ValueError: Dimensions must be equal, but are 128 and 64 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](Cast_1, Cast_3)' with input shapes: [?,128,128,1], [?,64,64,1].\n"
     ]
    }
   ],
   "source": [
    "# Model checkpoint\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [\n",
    "              tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "              tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
    "\n",
    "\n",
    "results = model.fit(X_train, Y_train, validation_data=(X_valid, Y_valid), batch_size=16, epochs=100, callbacks=callbacks,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
